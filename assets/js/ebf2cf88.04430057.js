(self.webpackChunksynapseml=self.webpackChunksynapseml||[]).push([[2010,150,9887,3148,4537,6877,2949,8617],{3905:function(e,a,t){"use strict";t.d(a,{Zo:function(){return i},kt:function(){return d}});var n=t(7294);function s(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function r(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function o(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?r(Object(t),!0).forEach((function(a){s(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function l(e,a){if(null==e)return{};var t,n,s=function(e,a){if(null==e)return{};var t,n,s={},r=Object.keys(e);for(n=0;n<r.length;n++)t=r[n],a.indexOf(t)>=0||(s[t]=e[t]);return s}(e,a);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)t=r[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(s[t]=e[t])}return s}var m=n.createContext({}),p=function(e){var a=n.useContext(m),t=a;return e&&(t="function"==typeof e?e(a):o(o({},a),e)),t},i=function(e){var a=p(e.components);return n.createElement(m.Provider,{value:a},e.children)},c={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},u=n.forwardRef((function(e,a){var t=e.components,s=e.mdxType,r=e.originalType,m=e.parentName,i=l(e,["components","mdxType","originalType","parentName"]),u=p(t),d=s,y=u["".concat(m,".").concat(d)]||u[d]||c[d]||r;return t?n.createElement(y,o(o({ref:a},i),{},{components:t})):n.createElement(y,o({ref:a},i))}));function d(e,a){var t=arguments,s=a&&a.mdxType;if("string"==typeof e||s){var r=t.length,o=new Array(r);o[0]=u;var l={};for(var m in a)hasOwnProperty.call(a,m)&&(l[m]=a[m]);l.originalType=e,l.mdxType="string"==typeof e?e:s,o[1]=l;for(var p=2;p<r;p++)o[p]=t[p];return n.createElement.apply(null,o)}return n.createElement.apply(null,t)}u.displayName="MDXCreateElement"},1332:function(e,a,t){"use strict";var n=t(7294);a.Z=function(e){var a=e.children,t=e.hidden,s=e.className;return n.createElement("div",{role:"tabpanel",hidden:t,className:s},a)}},5386:function(e,a,t){"use strict";t.d(a,{Z:function(){return c}});var n=t(7294),s=t(8578);var r=function(){var e=(0,n.useContext)(s.Z);if(null==e)throw new Error('"useUserPreferencesContext" is used outside of "Layout" component.');return e},o=t(6010),l="tabItem_2kG2",m="tabItemActive_3NDg";var p=37,i=39;var c=function(e){var a=e.lazy,t=e.block,s=e.defaultValue,c=e.values,u=e.groupId,d=e.className,y=r(),f=y.tabGroupChoices,b=y.setTabGroupChoices,g=(0,n.useState)(s),k=g[0],T=g[1],h=n.Children.toArray(e.children),v=[];if(null!=u){var x=f[u];null!=x&&x!==k&&c.some((function(e){return e.value===x}))&&T(x)}var S=function(e){var a=e.currentTarget,t=v.indexOf(a),n=c[t].value;T(n),null!=u&&(b(u,n),setTimeout((function(){var e,t,n,s,r,o,l,p;(e=a.getBoundingClientRect(),t=e.top,n=e.left,s=e.bottom,r=e.right,o=window,l=o.innerHeight,p=o.innerWidth,t>=0&&r<=p&&s<=l&&n>=0)||(a.scrollIntoView({block:"center",behavior:"smooth"}),a.classList.add(m),setTimeout((function(){return a.classList.remove(m)}),2e3))}),150))},N=function(e){var a,t;switch(e.keyCode){case i:var n=v.indexOf(e.target)+1;t=v[n]||v[0];break;case p:var s=v.indexOf(e.target)-1;t=v[s]||v[v.length-1]}null==(a=t)||a.focus()};return n.createElement("div",{className:"tabs-container"},n.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.Z)("tabs",{"tabs--block":t},d)},c.map((function(e){var a=e.value,t=e.label;return n.createElement("li",{role:"tab",tabIndex:k===a?0:-1,"aria-selected":k===a,className:(0,o.Z)("tabs__item",l,{"tabs__item--active":k===a}),key:a,ref:function(e){return v.push(e)},onKeyDown:N,onFocus:S,onClick:S},t)}))),a?(0,n.cloneElement)(h.filter((function(e){return e.props.value===k}))[0],{className:"margin-vert--md"}):n.createElement("div",{className:"margin-vert--md"},h.map((function(e,a){return(0,n.cloneElement)(e,{key:a,hidden:e.props.value!==k})}))))}},8578:function(e,a,t){"use strict";var n=(0,t(7294).createContext)(void 0);a.Z=n},1989:function(e,a,t){"use strict";var n=t(7294),s=t(2263);a.Z=function(e){var a=e.className,t=e.py,r=e.scala,o=e.sourceLink,l=(0,s.Z)().siteConfig.customFields.version,m="https://mmlspark.blob.core.windows.net/docs/"+l+"/pyspark/"+t,p="https://mmlspark.blob.core.windows.net/docs/"+l+"/scala/"+r;return n.createElement("table",null,n.createElement("tbody",null,n.createElement("tr",null,n.createElement("td",null,n.createElement("strong",null,"Python API: "),n.createElement("a",{href:m},a)),n.createElement("td",null,n.createElement("strong",null,"Scala API: "),n.createElement("a",{href:p},a)),n.createElement("td",null,n.createElement("strong",null,"Source: "),n.createElement("a",{href:o},a)))))}},1487:function(e,a,t){"use strict";t.r(a),t.d(a,{frontMatter:function(){return i},contentTitle:function(){return c},metadata:function(){return u},toc:function(){return d},default:function(){return f}});var n=t(2122),s=t(9756),r=(t(7294),t(3905)),o=t(5386),l=t(1332),m=t(1989),p=["components"],i={},c=void 0,u={unversionedId:"documentation/transformers/core/_Explainers",id:"documentation/transformers/core/_Explainers",isDocsHomePage:!1,title:"_Explainers",description:"\x3c!--",source:"@site/docs/documentation/transformers/core/_Explainers.md",sourceDirName:"documentation/transformers/core",slug:"/documentation/transformers/core/_Explainers",permalink:"/SynapseML/docs/next/documentation/transformers/core/_Explainers",version:"current",frontMatter:{}},d=[{value:"Explainers",id:"explainers",children:[{value:"ImageLIME",id:"imagelime",children:[]},{value:"ImageSHAP",id:"imageshap",children:[]},{value:"TabularLIME",id:"tabularlime",children:[]},{value:"TabularSHAP",id:"tabularshap",children:[]},{value:"TextLIME",id:"textlime",children:[]},{value:"TextSHAP",id:"textshap",children:[]},{value:"VectorLIME",id:"vectorlime",children:[]},{value:"VectorSHAP",id:"vectorshap",children:[]}]}],y={toc:d};function f(e){var a=e.components,t=(0,s.Z)(e,p);return(0,r.kt)("wrapper",(0,n.Z)({},y,t,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"explainers"},"Explainers"),(0,r.kt)("h3",{id:"imagelime"},"ImageLIME"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.explainers import *\nfrom synapse.ml.onnx import ONNXModel\n\nmodel = ONNXModel()\n\nlime = (ImageLIME()\n    .setModel(model)\n    .setOutputCol("weights")\n    .setInputCol("image")\n    .setCellSize(150.0)\n    .setModifier(50.0)\n    .setNumSamples(500)\n    .setTargetCol("probability")\n    .setTargetClassesCol("top2pred")\n    .setSamplingFraction(0.7))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.explainers._\nimport com.microsoft.azure.synapse.ml.onnx._\nimport spark.implicits._\n\nval model = (new ONNXModel())\n\nval lime = (new ImageLIME()\n    .setModel(model)\n    .setOutputCol("weights")\n    .setInputCol("image")\n    .setCellSize(150.0)\n    .setModifier(50.0)\n    .setNumSamples(500)\n    .setTargetCol("probability")\n    .setTargetClassesCol("top2pred")\n    .setSamplingFraction(0.7))\n')))),(0,r.kt)(m.Z,{className:"ImageLIME",py:"synapse.ml.explainers.html#module-synapse.ml.explainers.ImageLIME",scala:"com/microsoft/azure/synapse/ml/explainers/ImageLIME.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/explainers/ImageLIME.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"imageshap"},"ImageSHAP"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.explainers import *\nfrom synapse.ml.onnx import ONNXModel\n\nmodel = ONNXModel()\n\nshap = (\n    ImageSHAP()\n    .setModel(model)\n    .setOutputCol("shaps")\n    .setSuperpixelCol("superpixels")\n    .setInputCol("image")\n    .setCellSize(150.0)\n    .setModifier(50.0)\n    .setNumSamples(500)\n    .setTargetCol("probability")\n    .setTargetClassesCol("top2pred")\n)\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.explainers._\nimport com.microsoft.azure.synapse.ml.onnx._\nimport spark.implicits._\n\nval model = (new ONNXModel())\n\nval shap = (new ImageSHAP()\n    .setModel(model)\n    .setOutputCol("shaps")\n    .setSuperpixelCol("superpixels")\n    .setInputCol("image")\n    .setCellSize(150.0)\n    .setModifier(50.0)\n    .setNumSamples(500)\n    .setTargetCol("probability")\n    .setTargetClassesCol("top2pred")\n))\n')))),(0,r.kt)(m.Z,{className:"ImageSHAP",py:"synapse.ml.explainers.html#module-synapse.ml.explainers.ImageSHAP",scala:"com/microsoft/azure/synapse/ml/explainers/ImageSHAP.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/explainers/ImageSHAP.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"tabularlime"},"TabularLIME"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.explainers import *\nfrom synapse.ml.onnx import ONNXModel\n\nmodel = ONNXModel()\ndata = spark.createDataFrame([\n    (-6.0, 0),\n    (-5.0, 0),\n    (5.0, 1),\n    (6.0, 1)\n], ["col1", "label"])\n\nlime = (TabularLIME()\n    .setModel(model)\n    .setInputCols(["col1"])\n    .setOutputCol("weights")\n    .setBackgroundData(data)\n    .setKernelWidth(0.001)\n    .setNumSamples(1000)\n    .setTargetCol("probability")\n    .setTargetClasses([0, 1]))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.explainers._\nimport com.microsoft.azure.synapse.ml.onnx._\nimport spark.implicits._\n\nval model = (new ONNXModel())\nval data = Seq(\n  (-6.0, 0),\n  (-5.0, 0),\n  (5.0, 1),\n  (6.0, 1)\n).toDF("col1", "label")\n\nval lime = (new TabularLIME()\n    .setInputCols(Array("col1"))\n    .setOutputCol("weights")\n    .setBackgroundData(data)\n    .setKernelWidth(0.001)\n    .setNumSamples(1000)\n    .setModel(model)\n    .setTargetCol("probability")\n    .setTargetClasses(Array(0, 1)))\n')))),(0,r.kt)(m.Z,{className:"TabularLIME",py:"synapse.ml.explainers.html#module-synapse.ml.explainers.TabularLIME",scala:"com/microsoft/azure/synapse/ml/explainers/TabularLIME.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/explainers/TabularLIME.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"tabularshap"},"TabularSHAP"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.explainers import *\nfrom synapse.ml.onnx import ONNXModel\n\nmodel = ONNXModel()\ndata = spark.createDataFrame([\n    (-5.0, "a", -5.0, 0),\n    (-5.0, "b", -5.0, 0),\n    (5.0, "a", 5.0, 1),\n    (5.0, "b", 5.0, 1)\n]*100, ["col1", "label"])\n\nshap = (TabularSHAP()\n    .setInputCols(["col1", "col2", "col3"])\n    .setOutputCol("shapValues")\n    .setBackgroundData(data)\n    .setNumSamples(1000)\n    .setModel(model)\n    .setTargetCol("probability")\n    .setTargetClasses([1]))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.explainers._\nimport com.microsoft.azure.synapse.ml.onnx._\nimport spark.implicits._\n\nval model = (new ONNXModel())\nval data = (1 to 100).flatMap(_ => Seq(\n    (-5d, "a", -5d, 0),\n    (-5d, "b", -5d, 0),\n    (5d, "a", 5d, 1),\n    (5d, "b", 5d, 1)\n  )).toDF("col1", "col2", "col3", "label")\n\nval shap = (new TabularSHAP()\n    .setInputCols(Array("col1", "col2", "col3"))\n    .setOutputCol("shapValues")\n    .setBackgroundData(data)\n    .setNumSamples(1000)\n    .setModel(model)\n    .setTargetCol("probability")\n    .setTargetClasses(Array(1)))\n')))),(0,r.kt)(m.Z,{className:"TabularSHAP",py:"synapse.ml.explainers.html#module-synapse.ml.explainers.TabularSHAP",scala:"com/microsoft/azure/synapse/ml/explainers/TabularSHAP.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/explainers/TabularSHAP.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"textlime"},"TextLIME"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.explainers import *\nfrom synapse.ml.onnx import ONNXModel\n\nmodel = ONNXModel()\n\nlime = (TextLIME()\n    .setModel(model)\n    .setInputCol("text")\n    .setTargetCol("prob")\n    .setTargetClasses([1])\n    .setOutputCol("weights")\n    .setTokensCol("tokens")\n    .setSamplingFraction(0.7)\n    .setNumSamples(1000))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.explainers._\nimport com.microsoft.azure.synapse.ml.onnx._\nimport spark.implicits._\n\nval model = (new ONNXModel())\n\nval lime = (new TextLIME()\n    .setModel(model)\n    .setInputCol("text")\n    .setTargetCol("prob")\n    .setTargetClasses(Array(1))\n    .setOutputCol("weights")\n    .setTokensCol("tokens")\n    .setSamplingFraction(0.7)\n    .setNumSamples(1000))\n')))),(0,r.kt)(m.Z,{className:"TextLIME",py:"synapse.ml.explainers.html#module-synapse.ml.explainers.TextLIME",scala:"com/microsoft/azure/synapse/ml/explainers/TextLIME.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/explainers/TextLIME.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"textshap"},"TextSHAP"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.explainers import *\nfrom synapse.ml.onnx import ONNXModel\n\nmodel = ONNXModel()\n\nshap = (TextSHAP()\n    .setModel(model)\n    .setInputCol("text")\n    .setTargetCol("prob")\n    .setTargetClasses([1])\n    .setOutputCol("weights")\n    .setTokensCol("tokens")\n    .setNumSamples(1000))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.explainers._\nimport com.microsoft.azure.synapse.ml.onnx._\nimport spark.implicits._\n\nval model = (new ONNXModel())\n\nval shap = (new TextSHAP()\n    .setModel(model)\n    .setInputCol("text")\n    .setTargetCol("prob")\n    .setTargetClasses(Array(1))\n    .setOutputCol("weights")\n    .setTokensCol("tokens")\n    .setNumSamples(1000))\n')))),(0,r.kt)(m.Z,{className:"TextSHAP",py:"synapse.ml.explainers.html#module-synapse.ml.explainers.TextSHAP",scala:"com/microsoft/azure/synapse/ml/explainers/TextSHAP.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/explainers/TextSHAP.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"vectorlime"},"VectorLIME"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.explainers import *\nfrom synapse.ml.onnx import ONNXModel\n\nmodel = ONNXModel()\n\ndf = spark.createDataframe([\n  ([0.2729799734928408, -0.4637273304253777, 1.565593782147994], 4.541185129673482),\n  ([1.9511879801376864, 1.495644437589599, -0.4667847796501322], 0.19526424470709836)\n])\n\nlime = (VectorLIME()\n    .setModel(model)\n    .setBackgroundData(df)\n    .setInputCol("features")\n    .setTargetCol("label")\n    .setOutputCol("weights")\n    .setNumSamples(1000))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.explainers._\nimport spark.implicits._\nimport breeze.linalg.{*, DenseMatrix => BDM}\nimport breeze.stats.distributions.Rand\nimport org.apache.spark.ml.linalg.Vectors\nimport org.apache.spark.ml.regression.LinearRegression\n\nval d1 = 3\nval d2 = 1\nval coefficients: BDM[Double] = new BDM(d1, d2, Array(1.0, -1.0, 2.0))\n\nval df = {\n    val nRows = 100\n    val intercept: Double = math.random()\n\n    val x: BDM[Double] = BDM.rand(nRows, d1, Rand.gaussian)\n    val y = x * coefficients + intercept\n\n    val xRows = x(*, ::).iterator.toSeq.map(dv => Vectors.dense(dv.toArray))\n    val yRows = y(*, ::).iterator.toSeq.map(dv => dv(0))\n    xRows.zip(yRows).toDF("features", "label")\n  }\n\nval model: LinearRegressionModel = new LinearRegression().fit(df)\n\nval lime = (new VectorLIME()\n    .setModel(model)\n    .setBackgroundData(df)\n    .setInputCol("features")\n    .setTargetCol(model.getPredictionCol)\n    .setOutputCol("weights")\n    .setNumSamples(1000))\n')))),(0,r.kt)(m.Z,{className:"VectorLIME",py:"synapse.ml.explainers.html#module-synapse.ml.explainers.VectorLIME",scala:"com/microsoft/azure/synapse/ml/explainers/VectorLIME.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/explainers/VectorLIME.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"vectorshap"},"VectorSHAP"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.explainers import *\nfrom synapse.ml.onnx import ONNXModel\n\nmodel = ONNXModel()\n\nshap = (VectorSHAP()\n    .setModel(model)\n    .setInputCol("text")\n    .setTargetCol("prob")\n    .setTargetClasses([1])\n    .setOutputCol("weights")\n    .setTokensCol("tokens")\n    .setNumSamples(1000))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.explainers._\nimport spark.implicits._\nimport breeze.linalg.{*, DenseMatrix => BDM}\nimport breeze.stats.distributions.RandBasis\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.linalg.Vectors\n\nval randBasis = RandBasis.withSeed(123)\nval m: BDM[Double] = BDM.rand[Double](1000, 5, randBasis.gaussian)\nval l: BDV[Double] = m(*, ::).map {\n    row =>\n      if (row(2) + row(3) > 0.5) 1d else 0d\n  }\nval data = m(*, ::).iterator.zip(l.valuesIterator).map {\n    case (f, l) => (f.toSpark, l)\n  }.toSeq.toDF("features", "label")\n\nval model = new LogisticRegression()\n    .setFeaturesCol("features")\n    .setLabelCol("label")\n    .fit(data)\n\nval shap = (new VectorSHAP()\n    .setInputCol("features")\n    .setOutputCol("shapValues")\n    .setBackgroundData(data)\n    .setNumSamples(1000)\n    .setModel(model)\n    .setTargetCol("probability")\n    .setTargetClasses(Array(1))\n\nval infer = Seq(\n    Tuple1(Vectors.dense(1d, 1d, 1d, 1d, 1d))\n  ) toDF "features"\nval predicted = model.transform(infer)\ndisplay(shap.transform(predicted))\n')))),(0,r.kt)(m.Z,{className:"VectorSHAP",py:"synapse.ml.explainers.html#module-synapse.ml.explainers.VectorSHAP",scala:"com/microsoft/azure/synapse/ml/explainers/VectorSHAP.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/explainers/VectorSHAP.scala",mdxType:"DocTable"}))}f.isMDXComponent=!0},4513:function(e,a,t){"use strict";t.r(a),t.d(a,{frontMatter:function(){return i},contentTitle:function(){return c},metadata:function(){return u},toc:function(){return d},default:function(){return f}});var n=t(2122),s=t(9756),r=(t(7294),t(3905)),o=t(5386),l=t(1332),m=t(1989),p=["components"],i={},c=void 0,u={unversionedId:"documentation/transformers/core/_Featurize",id:"documentation/transformers/core/_Featurize",isDocsHomePage:!1,title:"_Featurize",description:"\x3c!--",source:"@site/docs/documentation/transformers/core/_Featurize.md",sourceDirName:"documentation/transformers/core",slug:"/documentation/transformers/core/_Featurize",permalink:"/SynapseML/docs/next/documentation/transformers/core/_Featurize",version:"current",frontMatter:{}},d=[{value:"Featurize",id:"featurize",children:[{value:"DataConversion",id:"dataconversion",children:[]},{value:"IndexToValue",id:"indextovalue",children:[]}]},{value:"Featurize Text",id:"featurize-text",children:[{value:"MultiNGram",id:"multingram",children:[]},{value:"PageSplitter",id:"pagesplitter",children:[]}]}],y={toc:d};function f(e){var a=e.components,t=(0,s.Z)(e,p);return(0,r.kt)("wrapper",(0,n.Z)({},y,t,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"featurize"},"Featurize"),(0,r.kt)("h3",{id:"dataconversion"},"DataConversion"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.featurize import *\n\ndf = spark.createDataFrame([\n    (True, 1, 2, 3, 4, 5.0, 6.0, "7", "8.0"),\n    (False, 9, 10, 11, 12, 14.5, 15.5, "16", "17.456"),\n    (True, -127, 345, 666, 1234, 18.91, 20.21, "100", "200.12345")\n], ["bool", "byte", "short", "int", "long", "float", "double", "intstring", "doublestring"])\n\ndc = (DataConversion()\n        .setCols(["byte"])\n        .setConvertTo("boolean"))\n\ndisplay(dc.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.featurize._\nimport spark.implicits._\n\nval df = Seq(\n    (true: Boolean, 1: Byte, 2: Short, 3: Integer, 4: Long, 5.0F, 6.0, "7", "8.0"),\n    (false, 9: Byte, 10: Short, 11: Integer, 12: Long, 14.5F, 15.5, "16", "17.456"),\n    (true, -127: Byte, 345: Short, Short.MaxValue + 100, (Int.MaxValue).toLong + 100, 18.91F, 20.21, "100", "200.12345"))\n    .toDF("bool", "byte", "short", "int", "long", "float", "double", "intstring", "doublestring")\n\nval dc = (new DataConversion()\n        .setCols(Array("byte"))\n        .setConvertTo("boolean"))\n\ndisplay(dc.transform(df))\n')))),(0,r.kt)(m.Z,{className:"DataConversion",py:"synapse.ml.featurize.html#module-synapse.ml.featurize.DataConversion",scala:"com/microsoft/azure/synapse/ml/featurize/DataConversion.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/featurize/DataConversion.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"indextovalue"},"IndexToValue"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.featurize import *\n\ndf = spark.createDataFrame([\n    (-3, 24, 0.32534, True, "piano"),\n    (1, 5, 5.67, False, "piano"),\n    (-3, 5, 0.32534, False, "guitar")\n], ["int", "long", "double", "bool", "string"])\n\ndf2 = ValueIndexer().setInputCol("string").setOutputCol("string_cat").fit(df).transform(df)\n\nitv = (IndexToValue()\n        .setInputCol("string_cat")\n        .setOutputCol("string_noncat"))\n\ndisplay(itv.transform(df2))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.featurize._\nimport spark.implicits._\n\nval df = Seq[(Int, Long, Double, Boolean, String)](\n    (-3, 24L, 0.32534, true, "piano"),\n    (1, 5L, 5.67, false, "piano"),\n    (-3, 5L, 0.32534, false, "guitar")).toDF("int", "long", "double", "bool", "string")\n\nval df2 = new ValueIndexer().setInputCol("string").setOutputCol("string_cat").fit(df).transform(df)\n\nval itv = (new IndexToValue()\n        .setInputCol("string_cat")\n        .setOutputCol("string_noncat"))\n\ndisplay(itv.transform(df2))\n')))),(0,r.kt)(m.Z,{className:"IndexToValue",py:"synapse.ml.featurize.html#module-synapse.ml.featurize.IndexToValue",scala:"com/microsoft/azure/synapse/ml/featurize/IndexToValue.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/featurize/IndexToValue.scala",mdxType:"DocTable"}),(0,r.kt)("h2",{id:"featurize-text"},"Featurize Text"),(0,r.kt)("h3",{id:"multingram"},"MultiNGram"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.featurize.text import *\nfrom pyspark.ml.feature import Tokenizer\n\ndfRaw = spark.createDataFrame([\n    (0, "Hi I"),\n    (1, "I wish for snow today"),\n    (2, "we Cant go to the park, because of the snow!"),\n    (3, ""),\n    (4, "1 2 3 4 5 6 7 8 9")\n], ["label", "sentence"])\n\ndfTok = (Tokenizer()\n    .setInputCol("sentence")\n    .setOutputCol("tokens")\n    .transform(dfRaw))\n\nmng = (MultiNGram()\n    .setLengths([1, 3, 4])\n    .setInputCol("tokens")\n    .setOutputCol("ngrams"))\n\ndisplay(mng.transform(dfTok))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.featurize.text._\nimport org.apache.spark.ml.feature.Tokenizer\nimport spark.implicits._\n\nval dfRaw = (Seq(\n    (0, "Hi I"),\n    (1, "I wish for snow today"),\n    (2, "we Cant go to the park, because of the snow!"),\n    (3, ""),\n    (4, (1 to 10).map(_.toString).mkString(" ")))\n    .toDF("label", "sentence"))\n\nval dfTok = (new Tokenizer()\n    .setInputCol("sentence")\n    .setOutputCol("tokens")\n    .transform(dfRaw))\n\nval mng = (new MultiNGram()\n    .setLengths(Array(1, 3, 4))\n    .setInputCol("tokens")\n    .setOutputCol("ngrams"))\n\ndisplay(mng.transform(dfTok))\n')))),(0,r.kt)(m.Z,{className:"MultiNGram",py:"synapse.ml.featurize.text.html#module-synapse.ml.featurize.text.MultiNGram",scala:"com/microsoft/azure/synapse/ml/featurize/text/MultiNGram.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/featurize/text/MultiNGram.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"pagesplitter"},"PageSplitter"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.featurize.text import *\n\ndf = spark.createDataFrame([\n    ("words words  words     wornssaa ehewjkdiw weijnsikjn xnh", ),\n    ("s s  s   s     s           s", ),\n    ("hsjbhjhnskjhndwjnbvckjbnwkjwenbvfkjhbnwevkjhbnwejhkbnvjkhnbndjkbnd", ),\n    ("hsjbhjhnskjhndwjnbvckjbnwkjwenbvfkjhbnwevkjhbnwejhkbnvjkhnbndjkbnd 190872340870271091309831097813097130i3u709781", ),\n    ("", ),\n    (None, )\n], ["text"])\n\nps = (PageSplitter()\n    .setInputCol("text")\n    .setMaximumPageLength(20)\n    .setMinimumPageLength(10)\n    .setOutputCol("pages"))\n\ndisplay(ps.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.featurize.text._\nimport spark.implicits._\n\nval df = Seq(\n    "words words  words     wornssaa ehewjkdiw weijnsikjn xnh",\n    "s s  s   s     s           s",\n    "hsjbhjhnskjhndwjnbvckjbnwkjwenbvfkjhbnwevkjhbnwejhkbnvjkhnbndjkbnd",\n    "hsjbhjhnskjhndwjnbvckjbnwkjwenbvfkjhbnwevkjhbnwejhkbnvjkhnbndjkbnd " +\n      "190872340870271091309831097813097130i3u709781",\n    "",\n    null\n  ).toDF("text")\n\nval ps = (new PageSplitter()\n    .setInputCol("text")\n    .setMaximumPageLength(20)\n    .setMinimumPageLength(10)\n    .setOutputCol("pages"))\n\ndisplay(ps.transform(df))\n')))),(0,r.kt)(m.Z,{className:"PageSplitter",py:"synapse.ml.featurize.text.html#module-synapse.ml.featurize.text.PageSplitter",scala:"com/microsoft/azure/synapse/ml/featurize/text/PageSplitter.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/featurize/text/PageSplitter.scala",mdxType:"DocTable"}))}f.isMDXComponent=!0},3890:function(e,a,t){"use strict";t.r(a),t.d(a,{frontMatter:function(){return i},contentTitle:function(){return c},metadata:function(){return u},toc:function(){return d},default:function(){return f}});var n=t(2122),s=t(9756),r=(t(7294),t(3905)),o=t(5386),l=t(1332),m=t(1989),p=["components"],i={},c=void 0,u={unversionedId:"documentation/transformers/core/_IO",id:"documentation/transformers/core/_IO",isDocsHomePage:!1,title:"_IO",description:"\x3c!--",source:"@site/docs/documentation/transformers/core/_IO.md",sourceDirName:"documentation/transformers/core",slug:"/documentation/transformers/core/_IO",permalink:"/SynapseML/docs/next/documentation/transformers/core/_IO",version:"current",frontMatter:{}},d=[{value:"IO",id:"io",children:[{value:"HTTPTransformer",id:"httptransformer",children:[]},{value:"SimpleHTTPTransformer",id:"simplehttptransformer",children:[]},{value:"JSONInputParser",id:"jsoninputparser",children:[]},{value:"JSONOutputParser",id:"jsonoutputparser",children:[]},{value:"StringOutputParser",id:"stringoutputparser",children:[]},{value:"CustomInputParser",id:"custominputparser",children:[]},{value:"CustomOutputParser",id:"customoutputparser",children:[]}]}],y={toc:d};function f(e){var a=e.components,t=(0,s.Z)(e,p);return(0,r.kt)("wrapper",(0,n.Z)({},y,t,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"io"},"IO"),(0,r.kt)("h3",{id:"httptransformer"},"HTTPTransformer"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.io.http import *\nfrom pyspark.sql.functions import udf, col\nfrom requests import Request\n\ndef world_bank_request(country):\n    return Request("GET", "http://api.worldbank.org/v2/country/{}?format=json".format(country))\n\ndf = (spark.createDataFrame([("br",), ("usa",)], ["country"])\n      .withColumn("request", http_udf(world_bank_request)(col("country"))))\n\nht = (HTTPTransformer()\n      .setConcurrency(3)\n      .setInputCol("request")\n      .setOutputCol("response"))\n\ndisplay(ht.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.io.http._\n\nval ht = (new HTTPTransformer()\n      .setConcurrency(3)\n      .setInputCol("request")\n      .setOutputCol("response"))\n')))),(0,r.kt)(m.Z,{className:"HTTPTransformer",py:"mmlspark.io.http.html#module-mmlspark.io.http.HTTPTransformer",scala:"com/microsoft/azure/synapse/ml/io/http/HTTPTransformer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/io/http/HTTPTransformer.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"simplehttptransformer"},"SimpleHTTPTransformer"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.io.http import *\nfrom pyspark.sql.types import StringType, StructType\n\nsht = (SimpleHTTPTransformer()\n        .setInputCol("data")\n        .setOutputParser(JSONOutputParser()\n            .setDataType(StructType().add("blah", StringType)))\n        .setUrl("PUT_YOUR_URL")\n        .setOutputCol("results")\n        .setConcurrency(3))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.io.http._\nimport org.apache.spark.sql.types.{StringType, StructType}\n\nval sht = (new SimpleHTTPTransformer()\n        .setInputCol("data")\n        .setOutputParser(new JSONOutputParser()\n            .setDataType(new StructType().add("blah", StringType)))\n        .setUrl("PUT_YOUR_URL")\n        .setOutputCol("results")\n        .setConcurrency(3))\n')))),(0,r.kt)(m.Z,{className:"SimpleHTTPTransformer",py:"mmlspark.io.http.html#module-mmlspark.io.http.SimpleHTTPTransformer",scala:"com/microsoft/azure/synapse/ml/io/http/SimpleHTTPTransformer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/io/http/SimpleHTTPTransformer.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"jsoninputparser"},"JSONInputParser"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.io.http import *\n\njsonIP = (JSONInputParser()\n      .setInputCol("data")\n      .setOutputCol("out")\n      .setUrl("PUT_YOUR_URL"))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.io.http._\n\nval jsonIP = (new JSONInputParser()\n      .setInputCol("data")\n      .setOutputCol("out")\n      .setUrl("PUT_YOUR_URL"))\n')))),(0,r.kt)(m.Z,{className:"JSONInputParser",py:"mmlspark.io.http.html#module-mmlspark.io.http.JSONInputParser",scala:"com/microsoft/azure/synapse/ml/io/http/JSONInputParser.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/io/http/JSONInputParser.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"jsonoutputparser"},"JSONOutputParser"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.io.http import *\nfrom pyspark.sql.types import StringType, StructType\n\njsonOP = (JSONOutputParser()\n      .setDataType(StructType().add("foo", StringType))\n      .setInputCol("unparsedOutput")\n      .setOutputCol("parsedOutput"))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.io.http._\nimport org.apache.spark.sql.types.{StringType, StructType}\n\nval jsonOP = (new JSONOutputParser()\n      .setDataType(new StructType().add("foo", StringType))\n      .setInputCol("unparsedOutput")\n      .setOutputCol("parsedOutput"))\n')))),(0,r.kt)(m.Z,{className:"JSONOutputParser",py:"mmlspark.io.http.html#module-mmlspark.io.http.JSONOutputParser",scala:"com/microsoft/azure/synapse/ml/io/http/JSONOutputParser.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/io/http/JSONOutputParser.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"stringoutputparser"},"StringOutputParser"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.io.http import *\n\nsop = (StringOutputParser()\n      .setInputCol("unparsedOutput")\n      .setOutputCol("out"))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.io.http._\n\nval sop = (new StringOutputParser()\n      .setInputCol("unparsedOutput")\n      .setOutputCol("out"))\n')))),(0,r.kt)(m.Z,{className:"StringOutputParser",py:"mmlspark.io.http.html#module-mmlspark.io.http.StringOutputParser",scala:"com/microsoft/azure/synapse/ml/io/http/StringOutputParser.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/io/http/StringOutputParser.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"custominputparser"},"CustomInputParser"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.io.http import *\n\ncip = (CustomInputParser()\n      .setInputCol("data")\n      .setOutputCol("out"))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.io.http._\n\nval cip = (new CustomInputParser()\n      .setInputCol("data")\n      .setOutputCol("out")\n      .setUDF({ x: Int => new HttpPost(s"http://$x") }))\n')))),(0,r.kt)(m.Z,{className:"CustomInputParser",py:"mmlspark.io.http.html#module-mmlspark.io.http.CustomInputParser",scala:"com/microsoft/azure/synapse/ml/io/http/CustomInputParser.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/io/http/CustomInputParser.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"customoutputparser"},"CustomOutputParser"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.io.http import *\n\ncop = (CustomOutputParser()\n      .setInputCol("unparsedOutput")\n      .setOutputCol("out"))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.io.http._\n\nval cop = (new CustomOutputParser()\n      .setInputCol("unparsedOutput")\n      .setOutputCol("out"))\n')))),(0,r.kt)(m.Z,{className:"CustomOutputParser",py:"mmlspark.io.http.html#module-mmlspark.io.http.CustomOutputParser",scala:"com/microsoft/azure/synapse/ml/io/http/CustomOutputParser.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/io/http/CustomOutputParser.scala",mdxType:"DocTable"}))}f.isMDXComponent=!0},9508:function(e,a,t){"use strict";t.r(a),t.d(a,{frontMatter:function(){return i},contentTitle:function(){return c},metadata:function(){return u},toc:function(){return d},default:function(){return f}});var n=t(2122),s=t(9756),r=(t(7294),t(3905)),o=t(5386),l=t(1332),m=t(1989),p=["components"],i={},c=void 0,u={unversionedId:"documentation/transformers/core/_Image",id:"documentation/transformers/core/_Image",isDocsHomePage:!1,title:"_Image",description:"\x3c!--",source:"@site/docs/documentation/transformers/core/_Image.md",sourceDirName:"documentation/transformers/core",slug:"/documentation/transformers/core/_Image",permalink:"/SynapseML/docs/next/documentation/transformers/core/_Image",version:"current",frontMatter:{}},d=[{value:"Image",id:"image",children:[{value:"ResizeImageTransformer",id:"resizeimagetransformer",children:[]},{value:"UnrollImage",id:"unrollimage",children:[]},{value:"UnrollBinaryImage",id:"unrollbinaryimage",children:[]}]}],y={toc:d};function f(e){var a=e.components,t=(0,s.Z)(e,p);return(0,r.kt)("wrapper",(0,n.Z)({},y,t,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"image"},"Image"),(0,r.kt)("h3",{id:"resizeimagetransformer"},"ResizeImageTransformer"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.image import *\n\n# images = (spark.read.format("image")\n#         .option("dropInvalid", True)\n#         .load("wasbs://datasets@mmlspark.blob.core.windows.net/LIME/greyscale.jpg"))\n\nrit = (ResizeImageTransformer()\n        .setOutputCol("out")\n        .setHeight(15)\n        .setWidth(10))\n\n# display(rit.transform(images))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.image._\nimport spark.implicits._\n\n// val images = (spark.read.format("image")\n//     .option("dropInvalid", true)\n//     .load("wasbs://datasets@mmlspark.blob.core.windows.net/LIME/greyscale.jpg"))\n\nval rit = (new ResizeImageTransformer()\n    .setOutputCol("out")\n    .setHeight(15)\n    .setWidth(10))\n\n// display(rit.transform(images))\n')))),(0,r.kt)(m.Z,{className:"ResizeImageTransformer",py:"mmlspark.image.html#module-mmlspark.image.ResizeImageTransformer",scala:"com/microsoft/azure/synapse/ml/image/ResizeImageTransformer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/image/ResizeImageTransformer.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"unrollimage"},"UnrollImage"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.image import *\nfrom azure.storage.blob import *\n\nimages = (spark.read.format("image")\n        .option("dropInvalid", True)\n        .load("wasbs://datasets@mmlspark.blob.core.windows.net/LIME/greyscale.jpg"))\n\nrit = (ResizeImageTransformer()\n        .setOutputCol("out")\n        .setHeight(15)\n        .setWidth(10))\n\npreprocessed = rit.transform(images)\n\nunroll = (UnrollImage()\n      .setInputCol(rit.getOutputCol)\n      .setOutputCol("final"))\n\ndisplay(unroll.transform(preprocessed))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.image._\nimport spark.implicits._\n\nval images = (spark.read.format("image")\n    .option("dropInvalid", true)\n    .load("wasbs://datasets@mmlspark.blob.core.windows.net/LIME/greyscale.jpg"))\n\nval rit = (new ResizeImageTransformer()\n    .setOutputCol("out")\n    .setHeight(15)\n    .setWidth(10))\n\nval preprocessed = rit.transform(images)\n\nval unroll = (new UnrollImage()\n      .setInputCol(rit.getOutputCol)\n      .setOutputCol("final"))\n\ndisplay(unroll.transform(preprocessed))\n')))),(0,r.kt)(m.Z,{className:"UnrollImage",py:"mmlspark.image.html#module-mmlspark.image.UnrollImage",scala:"com/microsoft/azure/synapse/ml/image/UnrollImage.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/image/UnrollImage.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"unrollbinaryimage"},"UnrollBinaryImage"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.image import *\n\nunroll = (UnrollBinaryImage()\n      .setInputCol("input_col")\n      .setOutputCol("final"))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.image._\nimport spark.implicits._\n\nval unroll = (new UnrollBinaryImage()\n        .setInputCol("input_col")\n        .setOutputCol("final"))\n\n')))),(0,r.kt)(m.Z,{className:"UnrollBinaryImage",py:"mmlspark.image.html#module-mmlspark.image.UnrollBinaryImage",scala:"com/microsoft/azure/synapse/ml/image/UnrollBinaryImage.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/image/UnrollBinaryImage.scala",mdxType:"DocTable"}))}f.isMDXComponent=!0},395:function(e,a,t){"use strict";t.r(a),t.d(a,{frontMatter:function(){return i},contentTitle:function(){return c},metadata:function(){return u},toc:function(){return d},default:function(){return f}});var n=t(2122),s=t(9756),r=(t(7294),t(3905)),o=t(5386),l=t(1332),m=t(1989),p=["components"],i={},c=void 0,u={unversionedId:"documentation/transformers/core/_Stages",id:"documentation/transformers/core/_Stages",isDocsHomePage:!1,title:"_Stages",description:"\x3c!--",source:"@site/docs/documentation/transformers/core/_Stages.md",sourceDirName:"documentation/transformers/core",slug:"/documentation/transformers/core/_Stages",permalink:"/SynapseML/docs/next/documentation/transformers/core/_Stages",version:"current",frontMatter:{}},d=[{value:"Stages",id:"stages",children:[{value:"Cacher",id:"cacher",children:[]},{value:"DropColumns",id:"dropcolumns",children:[]},{value:"EnsembleByKey",id:"ensemblebykey",children:[]},{value:"Explode",id:"explode",children:[]},{value:"Lambda",id:"lambda",children:[]},{value:"DynamicMiniBatchTransformer",id:"dynamicminibatchtransformer",children:[]},{value:"FixedMiniBatchTransformer",id:"fixedminibatchtransformer",children:[]},{value:"TimeIntervalMiniBatchTransformer",id:"timeintervalminibatchtransformer",children:[]},{value:"FlattenBatch",id:"flattenbatch",children:[]},{value:"RenameColumn",id:"renamecolumn",children:[]},{value:"Repartition",id:"repartition",children:[]},{value:"SelectColumns",id:"selectcolumns",children:[]},{value:"StratifiedRepartition",id:"stratifiedrepartition",children:[]},{value:"SummarizeData",id:"summarizedata",children:[]},{value:"TextPreprocessor",id:"textpreprocessor",children:[]},{value:"UDFTransformer",id:"udftransformer",children:[]},{value:"UnicodeNormalize",id:"unicodenormalize",children:[]}]}],y={toc:d};function f(e){var a=e.components,t=(0,s.Z)(e,p);return(0,r.kt)("wrapper",(0,n.Z)({},y,t,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"stages"},"Stages"),(0,r.kt)("h3",{id:"cacher"},"Cacher"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      (0, "guitars", "drums"),\n      (1, "piano", "trumpet"),\n      (2, "bass", "cymbals"),\n      (3, "guitars", "drums"),\n      (4, "piano", "trumpet"),\n      (5, "bass", "cymbals"),\n      (6, "guitars", "drums"),\n      (7, "piano", "trumpet"),\n      (8, "bass", "cymbals"),\n      (9, "guitars", "drums"),\n      (10, "piano", "trumpet"),\n      (11, "bass", "cymbals")\n      ], ["numbers", "words", "more"]))\n\ncacher = Cacher()\n\ndisplay(cacher.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = Seq(\n      (0, "guitars", "drums"),\n      (1, "piano", "trumpet"),\n      (2, "bass", "cymbals"),\n      (3, "guitars", "drums"),\n      (4, "piano", "trumpet"),\n      (5, "bass", "cymbals"),\n      (6, "guitars", "drums"),\n      (7, "piano", "trumpet"),\n      (8, "bass", "cymbals"),\n      (9, "guitars", "drums"),\n      (10, "piano", "trumpet"),\n      (11, "bass", "cymbals")\n    ).toDF("numbers", "words", "more")\n\nval cacher = new Cacher()\n\ndisplay(cacher.transform(df))\n')))),(0,r.kt)(m.Z,{className:"HTTPTransformer",py:"synapse.ml.stages.html#module-synapse.ml.stages.Cacher",scala:"com/microsoft/azure/synapse/ml/stages/Cacher.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/Cacher.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"dropcolumns"},"DropColumns"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      (0, 0.toDouble, "guitars", "drums", 1.toLong, true),\n      (1, 1.toDouble, "piano", "trumpet", 2.toLong, false),\n      (2, 2.toDouble, "bass", "cymbals", 3.toLong, true)\n      ], ["numbers", "doubles", "words", "more", "longs", "booleans"]))\n\ndc = DropColumns().setCols([])\n\ndisplay(dc.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (Seq(\n      (0, 0.toDouble, "guitars", "drums", 1.toLong, true),\n      (1, 1.toDouble, "piano", "trumpet", 2.toLong, false),\n      (2, 2.toDouble, "bass", "cymbals", 3.toLong, true))\n      .toDF("numbers", "doubles", "words", "more", "longs", "booleans"))\n\nval dc = new DropColumns().setCols(Array())\n\ndisplay(dc.transform(df))\n')))),(0,r.kt)(m.Z,{className:"DropColumns",py:"synapse.ml.stages.html#module-synapse.ml.stages.DropColumns",scala:"com/microsoft/azure/synapse/ml/stages/DropColumns.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/DropColumns.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"ensemblebykey"},"EnsembleByKey"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\nscoreDF = (spark.createDataFrame([\n      (0, "foo", 1.0, .1),\n      (1, "bar", 4.0, -2.0),\n      (1, "bar", 0.0, -3.0)\n      ], ["label1", "label2", "score1", "score2"]))\n\nva = VectorAssembler().setInputCols(["score1", "score2"]).setOutputCol("v1")\nscoreDF2 = va.transform(scoreDF)\n\nebk = EnsembleByKey().setKey("label1").setCol("score1")\n\ndisplay(ebk.transform(scoreDF2))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\nimport org.apache.spark.ml.feature.VectorAssembler\n\nval scoreDF = (Seq(\n      (0, "foo", 1.0, .1),\n      (1, "bar", 4.0, -2.0),\n      (1, "bar", 0.0, -3.0))\n      .toDF("label1", "label2", "score1", "score2"))\n\nval va = new VectorAssembler().setInputCols(Array("score1", "score2")).setOutputCol("v1")\nval scoreDF2 = va.transform(scoreDF)\n\nval ebk = new EnsembleByKey().setKey("label1").setCol("score1")\n\ndisplay(ebk.transform(scoreDF2))\n')))),(0,r.kt)(m.Z,{className:"EnsembleByKey",py:"synapse.ml.stages.html#module-synapse.ml.stages.EnsembleByKey",scala:"com/microsoft/azure/synapse/ml/stages/EnsembleByKey.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/EnsembleByKey.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"explode"},"Explode"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      (0, ["guitars", "drums"]),\n      (1, ["piano"]),\n      (2, [])\n      ], ["numbers", "words"]))\n\nexplode = Explode().setInputCol("words").setOutputCol("exploded")\n\ndisplay(explode.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (Seq(\n    (0, Seq("guitars", "drums")),\n    (1, Seq("piano")),\n    (2, Seq()))\n    .toDF("numbers", "words"))\n\nval explode = new Explode().setInputCol("words").setOutputCol("exploded")\n\ndisplay(explode.transform(df))\n')))),(0,r.kt)(m.Z,{className:"Explode",py:"synapse.ml.stages.html#module-synapse.ml.stages.Explode",scala:"com/microsoft/azure/synapse/ml/stages/Explode.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/Explode.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"lambda"},"Lambda"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\nfrom pyspark.sql.types import StringType, StructType\n\ndf = (spark.createDataFrame([\n      (0, 0.0, "guitars", "drums", 1, True),\n      (1, 1.0, "piano", "trumpet", 2, False),\n      (2, 2.0, "bass", "cymbals", 3, True)\n      ], ["numbers", "doubles", "words", "more", "longs", "booleans"]))\n\nl = (Lambda()\n      .setTransform(lambda df : df.select("numbers"))\n      .setTransformSchema(lambda schema : StructType([schema("numbers")])))\n\ndisplay(l.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\nimport org.apache.spark.sql.types.{StringType, StructType}\n\nval df = (Seq(\n      (0, 0.toDouble, "guitars", "drums", 1.toLong, true),\n      (1, 1.toDouble, "piano", "trumpet", 2.toLong, false),\n      (2, 2.toDouble, "bass", "cymbals", 3.toLong, true))\n      .toDF("numbers", "doubles", "words", "more", "longs", "booleans"))\n\nval lambda = (new Lambda()\n      .setTransform(df => df.select("numbers"))\n      .setTransformSchema(schema => new StructType(Array(schema("numbers")))))\n\ndisplay(lambda.transform(df))\n')))),(0,r.kt)(m.Z,{className:"Lambda",py:"synapse.ml.stages.html#module-mmlspark.stages.Lambda",scala:"com/microsoft/azure/synapse/ml/stages/Lambda.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/Lambda.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"dynamicminibatchtransformer"},"DynamicMiniBatchTransformer"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\nfrom pyspark.sql.types import StringType, StructType\n\ndf = (spark.createDataFrame([(_, "foo") for _ in range(1, 11)], ["in1", "in2"]))\n\ndmbt = DynamicMiniBatchTransformer()\n\ndisplay(dmbt.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (1 until 11).map(x => (x, "foo")).toDF("in1", "in2")\n\nval dmbt = new DynamicMiniBatchTransformer()\n\ndisplay(dmbt.transform(df))\n')))),(0,r.kt)(m.Z,{className:"DynamicMiniBatchTransformer",py:"mmlspark.stages.html#module-mmlspark.stages.DynamicMiniBatchTransformer",scala:"com/microsoft/azure/synapse/ml/stages/DynamicMiniBatchTransformer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/MiniBatchTransformer.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"fixedminibatchtransformer"},"FixedMiniBatchTransformer"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from synapse.ml.stages import *\n\nfmbt = (FixedMiniBatchTransformer()\n      .setBuffered(true)\n      .setBatchSize(3))\n"))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"import com.microsoft.azure.synapse.ml.stages._\n\nval fmbt = (new FixedMiniBatchTransformer()\n      .setBuffered(true)\n      .setBatchSize(3))\n")))),(0,r.kt)(m.Z,{className:"FixedMiniBatchTransformer",py:"mmlspark.stages.html#module-mmlspark.stages.FixedMiniBatchTransformer",scala:"com/microsoft/azure/synapse/ml/stages/FixedMiniBatchTransformer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/MiniBatchTransformer.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"timeintervalminibatchtransformer"},"TimeIntervalMiniBatchTransformer"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([(_, "foo") for _ in range(1, 11)], ["in1", "in2"]))\n\ntimbt = (TimeIntervalMiniBatchTransformer()\n        .setMillisToWait(1000)\n        .setMaxBatchSize(30))\n\ndisplay(timbt.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (1 until 11).map(x => (x, "foo")).toDF("in1", "in2")\n\nval timbt = (new TimeIntervalMiniBatchTransformer()\n        .setMillisToWait(1000)\n        .setMaxBatchSize(30))\n\ndisplay(timbt.transform(df))\n')))),(0,r.kt)(m.Z,{className:"TimeIntervalMiniBatchTransformer",py:"mmlspark.stages.html#module-mmlspark.stages.TimeIntervalMiniBatchTransformer",scala:"com/microsoft/azure/synapse/ml/stages/TimeIntervalMiniBatchTransformer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/MiniBatchTransformer.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"flattenbatch"},"FlattenBatch"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([(_, "foo") for _ in range(1, 11)], ["in1", "in2"]))\n\ntransDF = DynamicMiniBatchTransformer().transform(df)\n\nfb = FlattenBatch()\n\ndisplay(fb.transform(transDF))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (1 until 11).map(x => (x, "foo")).toDF("in1", "in2")\n\nval transDF = new DynamicMiniBatchTransformer().transform(df)\n\nval fb = new FlattenBatch()\n\ndisplay(fb.transform(transDF))\n')))),(0,r.kt)(m.Z,{className:"FlattenBatch",py:"mmlspark.stages.html#module-mmlspark.stages.FlattenBatch",scala:"com/microsoft/azure/synapse/ml/stages/FlattenBatch.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/MiniBatchTransformer.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"renamecolumn"},"RenameColumn"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      (0, 0.toDouble, "guitars", "drums", 1.toLong, true),\n      (1, 1.toDouble, "piano", "trumpet", 2.toLong, false),\n      (2, 2.toDouble, "bass", "cymbals", 3.toLong, true)\n], ["numbers", "doubles", "words", "more", "longs", "booleans"]))\n\nrc = RenameColumn().setInputCol("words").setOutputCol("numbers")\n\ndisplay(rc.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (Seq(\n      (0, 0.toDouble, "guitars", "drums", 1.toLong, true),\n      (1, 1.toDouble, "piano", "trumpet", 2.toLong, false),\n      (2, 2.toDouble, "bass", "cymbals", 3.toLong, true))\n      .toDF("numbers", "doubles", "words", "more", "longs", "booleans"))\n\nval rc = new RenameColumn().setInputCol("words").setOutputCol("numbers")\n\ndisplay(rc.transform(df))\n')))),(0,r.kt)(m.Z,{className:"RenameColumn",py:"mmlspark.stages.html#module-mmlspark.stages.RenameColumn",scala:"com/microsoft/azure/synapse/ml/stages/RenameColumn.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/RenameColumn.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"repartition"},"Repartition"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      (0, "guitars", "drums"),\n      (1, "piano", "trumpet"),\n      (2, "bass", "cymbals"),\n      (3, "guitars", "drums"),\n      (4, "piano", "trumpet"),\n      (5, "bass", "cymbals"),\n      (6, "guitars", "drums"),\n      (7, "piano", "trumpet"),\n      (8, "bass", "cymbals"),\n      (9, "guitars", "drums"),\n      (10, "piano", "trumpet"),\n      (11, "bass", "cymbals")\n], ["numbers", "words", "more"]))\n\nrepartition = Repartition().setN(1)\n\ndisplay(repartition.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (Seq(\n    (0, "guitars", "drums"),\n    (1, "piano", "trumpet"),\n    (2, "bass", "cymbals"),\n    (3, "guitars", "drums"),\n    (4, "piano", "trumpet"),\n    (5, "bass", "cymbals"),\n    (6, "guitars", "drums"),\n    (7, "piano", "trumpet"),\n    (8, "bass", "cymbals"),\n    (9, "guitars", "drums"),\n    (10, "piano", "trumpet"),\n    (11, "bass", "cymbals")\n  ).toDF("numbers", "words", "more"))\n\nval repartition = new Repartition().setN(1)\n\ndisplay(repartition.transform(df))\n')))),(0,r.kt)(m.Z,{className:"Repartition",py:"mmlspark.stages.html#module-mmlspark.stages.Repartition",scala:"com/microsoft/azure/synapse/ml/stages/Repartition.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/Repartition.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"selectcolumns"},"SelectColumns"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      (0, 0.0, "guitars", "drums", 1, True),\n      (1, 1.0, "piano", "trumpet", 2, False),\n      (2, 2.0, "bass", "cymbals", 3, True)\n], ["numbers", "words", "more"]))\n\nsc = SelectColumns().setCols(["words", "more"])\n\ndisplay(sc.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (Seq(\n      (0, 0.toDouble, "guitars", "drums", 1.toLong, true),\n      (1, 1.toDouble, "piano", "trumpet", 2.toLong, false),\n      (2, 2.toDouble, "bass", "cymbals", 3.toLong, true))\n      .toDF("numbers", "doubles", "words", "more", "longs", "booleans"))\n\nval sc = new SelectColumns().setCols(Array("words", "more"))\n\ndisplay(sc.transform(df))\n')))),(0,r.kt)(m.Z,{className:"SelectColumns",py:"mmlspark.stages.html#module-mmlspark.stages.SelectColumns",scala:"com/microsoft/azure/synapse/ml/stages/SelectColumns.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/SelectColumns.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"stratifiedrepartition"},"StratifiedRepartition"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      (0, "Blue", 2),\n      (0, "Red", 2),\n      (0, "Green", 2),\n      (1, "Purple", 2),\n      (1, "Orange", 2),\n      (1, "Indigo", 2),\n      (2, "Violet", 2),\n      (2, "Black", 2),\n      (2, "White", 2),\n      (3, "Gray", 2),\n      (3, "Yellow", 2),\n      (3, "Cerulean", 2)\n], ["values", "colors", "const"]))\n\nsr = StratifiedRepartition().setLabelCol("values").setMode("equal")\n\ndisplay(sr.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (Seq(\n    (0, "Blue", 2),\n    (0, "Red", 2),\n    (0, "Green", 2),\n    (1, "Purple", 2),\n    (1, "Orange", 2),\n    (1, "Indigo", 2),\n    (2, "Violet", 2),\n    (2, "Black", 2),\n    (2, "White", 2),\n    (3, "Gray", 2),\n    (3, "Yellow", 2),\n    (3, "Cerulean", 2)\n  ).toDF("values", "colors", "const"))\n\nval sr = new StratifiedRepartition().setLabelCol("values").setMode("equal")\n\ndisplay(sr.transform(df))\n')))),(0,r.kt)(m.Z,{className:"StratifiedRepartition",py:"mmlspark.stages.html#module-mmlspark.stages.StratifiedRepartition",scala:"com/microsoft/azure/synapse/ml/stages/StratifiedRepartition.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/StratifiedRepartition.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"summarizedata"},"SummarizeData"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      (0, 0.0, "guitars", "drums", 1, True),\n      (1, 1.0, "piano", "trumpet", 2, False),\n      (2, 2.0, "bass", "cymbals", 3, True)\n], ["numbers", "doubles", "words", "more", "longs", "booleans"]))\n\nsummary = SummarizeData()\n\ndisplay(summary.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (Seq(\n      (0, 0.toDouble, "guitars", "drums", 1.toLong, true),\n      (1, 1.toDouble, "piano", "trumpet", 2.toLong, false),\n      (2, 2.toDouble, "bass", "cymbals", 3.toLong, true))\n      .toDF("numbers", "doubles", "words", "more", "longs", "booleans"))\n\nval summary = new SummarizeData()\n\ndisplay(summary.transform(df))\n')))),(0,r.kt)(m.Z,{className:"SummarizeData",py:"mmlspark.stages.html#module-mmlspark.stages.SummarizeData",scala:"com/microsoft/azure/synapse/ml/stages/SummarizeData.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/SummarizeData.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"textpreprocessor"},"TextPreprocessor"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      ("The happy sad boy drank sap", ),\n      ("The hater sad doy drank sap", ),\n      ("foo", ),\n      ("The hater sad doy aABc0123456789Zz_", )\n], ["words1"]))\n\ntestMap = {"happy": "sad", "hater": "sap",\n      "sad": "sap", "sad doy": "sap"}\n\ntextPreprocessor = (TextPreprocessor()\n      .setNormFunc("lowerCase")\n      .setMap(testMap)\n      .setInputCol("words1")\n      .setOutputCol("out"))\n\ndisplay(textPreprocessor.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (Seq(\n    ("The happy sad boy drank sap", ),\n    ("The hater sad doy drank sap", ),\n    ("foo", ),\n    ("The hater sad doy aABc0123456789Zz_", ))\n    .toDF("words1"))\n\nval testMap = Map[String, String] (\n    "happy"   -> "sad",\n    "hater"   -> "sap",\n    "sad"     -> "sap",\n    "sad doy" -> "sap"\n  )\n\nval textPreprocessor = (new TextPreprocessor()\n      .setNormFunc("lowerCase")\n      .setMap(testMap)\n      .setInputCol("words1")\n      .setOutputCol("out"))\n\ndisplay(textPreprocessor.transform(df))\n')))),(0,r.kt)(m.Z,{className:"TextPreprocessor",py:"mmlspark.stages.html#module-mmlspark.stages.TextPreprocessor",scala:"com/microsoft/azure/synapse/ml/stages/TextPreprocessor.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/TextPreprocessor.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"udftransformer"},"UDFTransformer"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\nfrom pyspark.sql.functions import udf\n\ndf = (spark.createDataFrame([\n      (0, 0.0, "guitars", "drums", 1, True),\n      (1, 1.0, "piano", "trumpet", 2, False),\n      (2, 2.0, "bass", "cymbals", 3, True)\n], ["numbers", "doubles", "words", "more", "longs", "booleans"]))\n\nstringToIntegerUDF = udf(lambda x: 1)\n\nudfTransformer = (UDFTransformer()\n      .setUDF(stringToIntegerUDF)\n      .setInputCol("numbers")\n      .setOutputCol("out"))\n\ndisplay(udfTransformer.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\nimport org.apache.spark.sql.functions.udf\n\nval df = (Seq(\n      (0, 0.toDouble, "guitars", "drums", 1.toLong, true),\n      (1, 1.toDouble, "piano", "trumpet", 2.toLong, false),\n      (2, 2.toDouble, "bass", "cymbals", 3.toLong, true))\n      .toDF("numbers", "doubles", "words", "more", "longs", "booleans"))\n\nval stringToIntegerUDF = udf((_: String) => 1)\n\nval udfTransformer = (new UDFTransformer()\n      .setUDF(stringToIntegerUDF)\n      .setInputCol("numbers")\n      .setOutputCol("out"))\n\ndisplay(udfTransformer.transform(df))\n')))),(0,r.kt)(m.Z,{className:"UDFTransformer",py:"mmlspark.stages.html#module-mmlspark.stages.UDFTransformer",scala:"com/microsoft/azure/synapse/ml/stages/UDFTransformer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/UDFTransformer.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"unicodenormalize"},"UnicodeNormalize"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      ("Sch\xf6n", 1),\n      ("Scho\\u0308n", 1),\n      (None, 1)\n], ["words1", "dummy"]))\n\nunicodeNormalize = (UnicodeNormalize()\n      .setForm("NFC")\n      .setInputCol("words1")\n      .setOutputCol("norm1"))\n\ndisplay(unicodeNormalize.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (Seq(\n    ("Sch\xf6n", 1),\n    ("Scho\\u0308n", 1),\n    (null, 1))\n    .toDF("words1", "dummy"))\n\nval unicodeNormalize = (new UnicodeNormalize()\n      .setForm("NFC")\n      .setInputCol("words1")\n      .setOutputCol("norm1"))\n\ndisplay(unicodeNormalize.transform(df))\n')))),(0,r.kt)(m.Z,{className:"UnicodeNormalize",py:"mmlspark.stages.html#module-mmlspark.stages.UnicodeNormalize",scala:"com/microsoft/azure/synapse/ml/stages/UnicodeNormalize.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/UnicodeNormalize.scala",mdxType:"DocTable"}))}f.isMDXComponent=!0},7768:function(e,a,t){"use strict";t.r(a),t.d(a,{frontMatter:function(){return i},contentTitle:function(){return c},metadata:function(){return u},toc:function(){return d},default:function(){return f}});var n=t(2122),s=t(9756),r=(t(7294),t(3905)),o=t(5386),l=t(1332),m=t(1989),p=["components"],i={},c=void 0,u={unversionedId:"documentation/transformers/core/_SuperpixelTransformer",id:"documentation/transformers/core/_SuperpixelTransformer",isDocsHomePage:!1,title:"_SuperpixelTransformer",description:"\x3c!--",source:"@site/docs/documentation/transformers/core/_SuperpixelTransformer.md",sourceDirName:"documentation/transformers/core",slug:"/documentation/transformers/core/_SuperpixelTransformer",permalink:"/SynapseML/docs/next/documentation/transformers/core/_SuperpixelTransformer",version:"current",frontMatter:{}},d=[{value:"LIME",id:"lime",children:[{value:"SuperpixelTransformer",id:"superpixeltransformer",children:[]}]}],y={toc:d};function f(e){var a=e.components,t=(0,s.Z)(e,p);return(0,r.kt)("wrapper",(0,n.Z)({},y,t,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"lime"},"LIME"),(0,r.kt)("h3",{id:"superpixeltransformer"},"SuperpixelTransformer"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.lime import *\n\nspt = (SuperpixelTransformer()\n      .setInputCol("images"))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.lime._\n\nval spt = (new SuperpixelTransformer()\n      .setInputCol("images"))\n')))),(0,r.kt)(m.Z,{className:"SuperpixelTransformer",py:"mmlspark.lime.html#module-mmlspark.lime.SuperpixelTransformer",scala:"com/microsoft/azure/synapse/ml/lime/SuperpixelTransformer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/lime/SuperpixelTransformer.scala",mdxType:"DocTable"}))}f.isMDXComponent=!0},2173:function(e,a,t){"use strict";t.r(a),t.d(a,{frontMatter:function(){return i},contentTitle:function(){return c},metadata:function(){return u},toc:function(){return d},default:function(){return f}});var n=t(2122),s=t(9756),r=(t(7294),t(3905)),o=t(5386),l=t(1332),m=t(1989),p=["components"],i={},c=void 0,u={unversionedId:"documentation/transformers/core/_Train",id:"documentation/transformers/core/_Train",isDocsHomePage:!1,title:"_Train",description:"\x3c!--",source:"@site/docs/documentation/transformers/core/_Train.md",sourceDirName:"documentation/transformers/core",slug:"/documentation/transformers/core/_Train",permalink:"/SynapseML/docs/next/documentation/transformers/core/_Train",version:"current",frontMatter:{}},d=[{value:"Train",id:"train",children:[{value:"ComputeModelStatistics",id:"computemodelstatistics",children:[]},{value:"ComputePerInstanceStatistics",id:"computeperinstancestatistics",children:[]}]}],y={toc:d};function f(e){var a=e.components,t=(0,s.Z)(e,p);return(0,r.kt)("wrapper",(0,n.Z)({},y,t,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"train"},"Train"),(0,r.kt)("h3",{id:"computemodelstatistics"},"ComputeModelStatistics"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.train import *\nfrom numpy import random\n\ndf = spark.createDataFrame(\n      [(random.rand(), random.rand()) for _ in range(4096)], ["label", "prediction"]\n)\n\ncms = (ComputeModelStatistics()\n      .setLabelCol("label")\n      .setScoredLabelsCol("prediction")\n      .setEvaluationMetric("classification"))\n\ndisplay(cms.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.train._\nimport scala.util.Random\n\nval rand = new Random(1337)\nval df = (Seq.fill(4096)(rand.nextDouble())\n      .zip(Seq.fill(4096)(rand.nextDouble()))\n      .toDF("label", "prediction"))\n\nval cms = (new ComputeModelStatistics()\n      .setLabelCol("label")\n      .setScoredLabelsCol("prediction")\n      .setEvaluationMetric("classification"))\n\ndisplay(cms.transform(df))\n')))),(0,r.kt)(m.Z,{className:"ComputeModelStatistics",py:"mmlspark.train.html#module-mmlspark.train.ComputeModelStatistics",scala:"com/microsoft/azure/synapse/ml/train/ComputeModelStatistics.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/train/ComputeModelStatistics.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"computeperinstancestatistics"},"ComputePerInstanceStatistics"),(0,r.kt)(o.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.train import *\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import FastVectorAssembler\n\nlogisticRegression = (LogisticRegression()\n      .setRegParam(0.3)\n      .setElasticNetParam(0.8)\n      .setMaxIter(10)\n      .setLabelCol("label")\n      .setPredictionCol("LogRegScoredLabelsCol")\n      .setRawPredictionCol("LogRegScoresCol")\n      .setProbabilityCol("LogRegProbCol")\n      .setFeaturesCol("features"))\n\ndataset = (spark.createDataFrame([\n    (0.0, 2, 0.50, 0.60, 0.0),\n    (1.0, 3, 0.40, 0.50, 1.0),\n    (2.0, 4, 0.78, 0.99, 2.0),\n    (3.0, 5, 0.12, 0.34, 3.0),\n    (0.0, 1, 0.50, 0.60, 0.0),\n    (1.0, 3, 0.40, 0.50, 1.0),\n    (2.0, 3, 0.78, 0.99, 2.0),\n    (3.0, 4, 0.12, 0.34, 3.0),\n    (0.0, 0, 0.50, 0.60, 0.0),\n    (1.0, 2, 0.40, 0.50, 1.0),\n    (2.0, 3, 0.78, 0.99, 2.0),\n    (3.0, 4, 0.12, 0.34, 3.0)],\n    ["label", "col1", "col2", "col3", "prediction"]))\n\nassembler = (FastVectorAssembler()\n      .setInputCols(["col1", "col2", "col3"])\n      .setOutputCol("features"))\nassembledDataset = assembler.transform(dataset)\nmodel = logisticRegression.fit(assembledDataset)\nscoredData = model.transform(assembledDataset)\n\ncps = (ComputePerInstanceStatistics()\n      .setLabelCol("label")\n      .setScoredLabelsCol("LogRegScoredLabelsCol")\n      .setScoresCol("LogRegScoresCol")\n      .setScoredProbabilitiesCol("LogRegProbCol")\n      .setEvaluationMetric("classification"))\n\ndisplay(cps.transform(scoredData))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.train._\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.feature.FastVectorAssembler\n\nval logisticRegression = (new LogisticRegression()\n      .setRegParam(0.3)\n      .setElasticNetParam(0.8)\n      .setMaxIter(10)\n      .setLabelCol("label")\n      .setPredictionCol("LogRegScoredLabelsCol")\n      .setRawPredictionCol("LogRegScoresCol")\n      .setProbabilityCol("LogRegProbCol")\n      .setFeaturesCol("features"))\n\nval dataset = spark.createDataFrame(Seq(\n    (0.0, 2, 0.50, 0.60, 0.0),\n    (1.0, 3, 0.40, 0.50, 1.0),\n    (2.0, 4, 0.78, 0.99, 2.0),\n    (3.0, 5, 0.12, 0.34, 3.0),\n    (0.0, 1, 0.50, 0.60, 0.0),\n    (1.0, 3, 0.40, 0.50, 1.0),\n    (2.0, 3, 0.78, 0.99, 2.0),\n    (3.0, 4, 0.12, 0.34, 3.0),\n    (0.0, 0, 0.50, 0.60, 0.0),\n    (1.0, 2, 0.40, 0.50, 1.0),\n    (2.0, 3, 0.78, 0.99, 2.0),\n    (3.0, 4, 0.12, 0.34, 3.0)))\n    .toDF("label", "col1", "col2", "col3", "prediction")\n\nval assembler = (new FastVectorAssembler()\n      .setInputCols(Array("col1", "col2", "col3"))\n      .setOutputCol("features"))\nval assembledDataset = assembler.transform(dataset)\nval model = logisticRegression.fit(assembledDataset)\nval scoredData = model.transform(assembledDataset)\n\nval cps = (new ComputePerInstanceStatistics()\n      .setLabelCol("label")\n      .setScoredLabelsCol("LogRegScoredLabelsCol")\n      .setScoresCol("LogRegScoresCol")\n      .setScoredProbabilitiesCol("LogRegProbCol")\n      .setEvaluationMetric("classification"))\n\ndisplay(cps.transform(scoredData))\n')))),(0,r.kt)(m.Z,{className:"ComputePerInstanceStatistics",py:"mmlspark.train.html#module-mmlspark.train.ComputePerInstanceStatistics",scala:"com/microsoft/azure/synapse/ml/train/ComputePerInstanceStatistics.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/train/ComputePerInstanceStatistics.scala",mdxType:"DocTable"}))}f.isMDXComponent=!0},4850:function(e,a,t){"use strict";t.r(a),t.d(a,{frontMatter:function(){return y},contentTitle:function(){return f},metadata:function(){return b},toc:function(){return g},default:function(){return T}});var n=t(2122),s=t(9756),r=(t(7294),t(3905)),o=t(1487),l=t(4513),m=t(9508),p=t(3890),i=t(7768),c=t(395),u=t(2173),d=["components"],y={title:"Transformers - Core",sidebar_label:"Core",hide_title:!0},f=void 0,b={unversionedId:"documentation/transformers/transformers_core",id:"documentation/transformers/transformers_core",isDocsHomePage:!1,title:"Transformers - Core",description:"export const toc = [...ExplainersTOC, ...FeaturizeTOC, ...ImageTOC,",source:"@site/docs/documentation/transformers/transformers_core.md",sourceDirName:"documentation/transformers",slug:"/documentation/transformers/transformers_core",permalink:"/SynapseML/docs/next/documentation/transformers/transformers_core",version:"current",frontMatter:{title:"Transformers - Core",sidebar_label:"Core",hide_title:!0},sidebar:"docs",previous:{title:"Cognitive",permalink:"/SynapseML/docs/next/documentation/transformers/transformers_cognitive"},next:{title:"OpenCV",permalink:"/SynapseML/docs/next/documentation/transformers/transformers_opencv"}},g=[].concat(o.toc,l.toc,m.toc,p.toc,i.toc,c.toc,u.toc),k={toc:g};function T(e){var a=e.components,t=(0,s.Z)(e,d);return(0,r.kt)("wrapper",(0,n.Z)({},k,t,{components:a,mdxType:"MDXLayout"}),(0,r.kt)(o.default,{mdxType:"Explainers"}),(0,r.kt)(l.default,{mdxType:"Featurize"}),(0,r.kt)(m.default,{mdxType:"Image"}),(0,r.kt)(p.default,{mdxType:"IO"}),(0,r.kt)(i.default,{mdxType:"SuperpixelTransformer"}),(0,r.kt)(c.default,{mdxType:"Stages"}),(0,r.kt)(u.default,{mdxType:"Train"}))}T.isMDXComponent=!0},6010:function(e,a,t){"use strict";function n(e){var a,t,s="";if("string"==typeof e||"number"==typeof e)s+=e;else if("object"==typeof e)if(Array.isArray(e))for(a=0;a<e.length;a++)e[a]&&(t=n(e[a]))&&(s&&(s+=" "),s+=t);else for(a in e)e[a]&&(s&&(s+=" "),s+=a);return s}function s(){for(var e,a,t=0,s="";t<arguments.length;)(e=arguments[t++])&&(a=n(e))&&(s&&(s+=" "),s+=a);return s}t.d(a,{Z:function(){return s}})}}]);